{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Interfacing Between pandas and Model Code\n",
    "A common workflow for model development: \n",
    "- use pandas for data loading and cleaning \n",
    "- Use  modeling library (`scikit-learn`, `statsmodels`) to build the model . \n",
    "    - feature engineering: data transformation.  The data aggregation and GroupBy tools  are used often in a feature engineering context.\n",
    "\n",
    "The point of contact between `pandas` and `other analysis libraries` is usually `NumPy` arrays. To turn a DataFrame into a NumPy array, use the `to_numpy` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert back to a DataFrame, as you may recall from earlier chapters, you can pass a two-dimensional ndarray with optional column names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_numpy` method is intended to be used when your data is homogeneousâ€”for example, all numeric types. If you have heterogeneous data, the result will be an ndarray of Python objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 = pd.DataFrame(data.to_numpy(), columns=['one', 'two', 'three'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3 = data.copy() #deep copy. changes to df3 will not affect the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some models, you may wish to use only a subset of the columns. I recommend using `loc` indexing with `to_numpy`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some libraries have native support for pandas and do some of this work for you automatically: converting to NumPy from DataFrame and attaching model parameter names to the columns of output tables or Series. In other cases, you will have to perform this \"metadata management\" manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data['category'] = pd.Categorical(['a', 'b', 'a', 'a', 'b'],\n",
    "                                  categories=['a', 'b']) #categories argument can be omitted here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to replace the `'category'` column with dummy variables, we create dummy variables, drop the 'category' column, and then join the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dummies = pd.get_dummies(data.category, prefix='category',\n",
    "                         dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_with_dummies = data.drop('category', axis=1).join(dummies) #left-join by default on index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some nuances to fitting certain statistical models with dummy variables. It may be simpler and less error-prone to use `Patsy` when you have more than simple numeric columns.\n",
    "\n",
    "## 12.2 Creating Model Descriptions with Patsy\n",
    "`Patsy` is a Python library for describing statistical models (especially linear models) with a string-based \"formula syntax,\" which is inspired by (but not exactly the same as) the formula syntax used by the `R` and `S` statistical programming languages. It is installed automatically when you install `statsmodels`:\n",
    "\n",
    "`conda install statsmodels`\n",
    "Patsy is well supported for specifying linear models in `statsmodels`.  `Patsy`'s formulas are a special string syntax that looks like:\n",
    "\n",
    "`y ~ x0 + x1`\n",
    "The syntax `a + b` does not mean to add `a` to `b`, but rather that these are terms in the design matrix created for the model. The `patsy.dmatrices` function takes a formula string along with a dataset (which can be a DataFrame or a dictionary of arrays) and produces design matrices for a linear model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import patsy\n",
    "y, X = patsy.dmatrices('y ~ x0 + x1', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These `Patsy` DesignMatrix instances are NumPy ndarrays with additional metadata:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wonder where the `Intercept` term came from. This is a convention for linear models like ordinary least squares (OLS) regression. You can suppress the intercept by adding the term `+ 0` to the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "patsy.dmatrices('y ~ x0 + x1 + 0', data)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Patsy objects can be passed directly into algorithms like `numpy.linalg.lstsq`, which performs an ordinary least squares regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coef, resid, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "#rcond: specify the cutoff for small singular values\n",
    "#resid: RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model metadata is retained in the `design_info` attribute, so you can reattach the model column names to the fitted coefficients to obtain a Series, for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.design_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.design_info.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations in Patsy Formulas\n",
    "You can mix Python code into your Patsy formulas; when evaluating the formula, the library will try to find the functions you use in the enclosing scope:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('y ~ x0 + np.log(np.abs(x1) + 1)', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some commonly used variable transformations include standardizing (to mean 0 and variance 1) and centering (subtracting the mean). Patsy has built-in functions for this purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('y ~ standardize(x0) + center(x1)', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of a modeling process, you may fit a model on one dataset, then evaluate the model based on another. This might be a hold-out portion or new data that is observed later. When applying transformations like center and standardize, you should be careful when using the model to form predications based on new data. These are called **stateful transformations**, because you must use statistics like the mean or standard deviation of the original dataset when transforming a new dataset.\n",
    "\n",
    "The `patsy.build_design_matrices` function can apply transformations to new out-of-sample data using the saved information from the original in-sample dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_X = patsy.build_design_matrices([X.design_info], new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the plus symbol (+) in the context of Patsy formulas does not mean addition, when you want to add columns from a dataset by name, you must wrap them in the special `I` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('y ~ I(x0 + x1)', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patsy has several other built-in transforms in the `patsy.builtins` module. See the online documentation for more.\n",
    "\n",
    "### Categorical Data and Patsy\n",
    "Nonnumeric data can be transformed for a model design matrix in many different ways. When you use nonnumeric terms in a Patsy formula, they are converted to **dummy variables** by default. If there is an intercept, one of the levels will be left out to avoid collinearity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('v2 ~ key1', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you omit the intercept from the model, then columns for each category value will be included in the model design matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('v2 ~ key1 + 0', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric columns can be interpreted as categorical with the `C` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('v2 ~ C(key2)', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're using multiple categorical terms in a model, things can be more complicated, as you can include interaction terms of the form `key1:key2`, which can be used, for example, in analysis of variance (ANOVA) models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data['key2'] = data['key2'].map({0: 'zero', 1: 'one'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, X = patsy.dmatrices('v2 ~ key1 + key2 + key1:key2', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Introduction to statsmodels\n",
    "`statsmodels` is a Python library for fitting many kinds of statistical models, performing statistical tests, and data exploration and visualization. statsmodels contains more \"classical\" frequentist statistical methods, while Bayesian methods and machine learning models are found in other libraries.\n",
    "\n",
    "Some kinds of models found in `statsmodels` include:\n",
    "\n",
    "Linear models, generalized linear models, and robust linear models\n",
    "\n",
    "Linear mixed effects models\n",
    "\n",
    "Analysis of variance (ANOVA) methods\n",
    "\n",
    "Time series processes and state space models\n",
    "\n",
    "Generalized method of moments\n",
    "\n",
    "### Estimating Linear Models\n",
    "There are several kinds of linear regression models in statsmodels, from the more basic (e.g., ordinary least squares) to more complex (e.g., iteratively reweighted least squares).\n",
    "\n",
    "Linear models in statsmodels have two different main interfaces: array based and formula based. These are accessed through these API module imports:\n",
    "```\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "```\n",
    "\n",
    "To show how to use these, we generate a linear model from some random data. Run the following code in a Jupyter cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear model is generally fitted with an intercept term, as we saw before with Patsy. The `sm.add_constant` function can add an intercept column to an existing matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_model = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = sm.OLS(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter names here have been given the generic names x1, x2, and so on. Suppose instead that all of the model parameters are in a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.OLS(y, X_model).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm.OLS(y, X_model).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results.tvalues # t-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how statsmodels has returned results as Series with the DataFrame column names attached. We also do not need to use add_constant when using formulas and pandas objects.\n",
    "\n",
    "Given new out-of-sample data, you can compute predicted values given the estimated model parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results.predict(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Time Series Processes\n",
    "Another class of models in statsmodels is for time series analysis. Among these are autoregressive processes, Kalman filtering and other state space models, and multivariate autoregressive models.\n",
    "\n",
    "Let's simulate some time series data with an autoregressive structure and noise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has an `AR(2)` structure (two lags) with parameters 0.8 and â€“0.4. When you fit an AR model, you may not know the number of lagged terms to include, so you can fit the model with some larger number of lags:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "MAXLAGS = 5\n",
    "model = AutoReg(values, MAXLAGS)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated parameters in the results have the intercept first, and the estimates for the first two lags next:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Introduction to scikit-learn\n",
    "`scikit-learn` is one of the most widely used and trusted general-purpose Python machine learning toolkits. It contains a broad selection of standard **supervised** and **unsupervised** machine learning methods, with tools for model selection and evaluation, data transformation, data loading, and model persistence. These models can be used for classification, clustering, prediction, and other common tasks. You can install scikit-learn from conda like so:\n",
    "\n",
    "`conda install scikit-learn`\n",
    "\n",
    " use a now-classic dataset from a Kaggle competition about passenger survival rates on the Titanic in 1912. We load the training and test datasets using pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics and machine learning examples like this one, a typical task is to predict whether a passenger would survive based on features in the data. A model is fitted on a training dataset and then evaluated on an out-of-sample testing dataset.\n",
    "\n",
    "use the median of the training dataset to fill the nulls in both tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "impute_value = train['Age'].median()\n",
    "train['Age'] = train['Age'].fillna(impute_value)\n",
    "test['Age'] = test['Age'].fillna(impute_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to specify our models. I add a column IsFemale as an encoded version of the 'Sex' column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train['IsFemale'] = (train['Sex'] == 'female').astype(int)\n",
    "test['IsFemale'] = (test['Sex'] == 'female').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we decide on some model variables and create NumPy arrays:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictors = ['Pclass', 'IsFemale', 'Age']\n",
    "\n",
    "X_train = train[predictors].to_numpy()\n",
    "X_test = test[predictors].to_numpy()\n",
    "y_train = train['Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had the true values for the test dataset, you could compute an accuracy percentage or some other error metric:\n",
    "\n",
    "`(y_true == y_predict).mean()`\n",
    "\n",
    "In practice, there are often many additional layers of complexity in model training. Many models have parameters that can be tuned, and there are techniques such as cross-validation that can be used for parameter tuning to avoid overfitting to the training data. This can often yield better predictive performance or robustness on new data.\n",
    "\n",
    "Cross-validation works by splitting the training data to simulate out-of-sample prediction. Based on a model accuracy score like mean squared error, you can perform a grid search on model parameters. Some models, like logistic regression, have estimator classes with built-in cross-validation. For example, the LogisticRegressionCV class can be used with a parameter indicating how fine-grained of a grid search to do on the model regularization parameter `C`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "model_cv = LogisticRegressionCV(Cs=10) # 10 values in the log scale between 1e-4, 1e4. C=inverse of the regularization.\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do cross-validation by hand, you can use the `cross_val_score` helper function, which handles the data splitting process. For example, to cross-validate our model with four nonoverlapping splits of the training data, we can do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression(C=10)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
