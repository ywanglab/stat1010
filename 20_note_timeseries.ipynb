{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Date and Time Data Types and Tools\n",
    "The Python standard library includes data types for date and time data, as well as calendar-related functionality. The `datetime`, `time`, and `calendar` modules are the main places to start. The `datetime.datetime` type, or simply datetime, is widely used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now.year, now.month, now.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datetime` stores both the date and time down to the microsecond. `datetime.timedelta`, or simply `timedelta`, represents the temporal difference between two datetime objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\n",
    "#datetime(year, month, day[, hour[, minute[, second[, microsecond[, tzinfo]]]]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "delta.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add (or subtract) a timedelta or multiple thereof to a datetime object to yield a new shifted object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datetime import timedelta\n",
    "start = datetime(2011, 1, 7)\n",
    "start + timedelta(12)\n",
    "#timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start - 2 * timedelta(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 11.1: Types in the datetime module\n",
    "Type\t|Description\n",
    "|:-----------|:--------------------------------------------------|\n",
    "date|\tStore calendar date (year, month, day) using the Gregorian calendar\n",
    "time\t|Store time of day as hours, minutes, seconds, and microseconds\n",
    "datetime|\tStore both date and time\n",
    "timedelta|\tThe difference between two datetime values (as days, seconds, and microseconds)\n",
    "tzinfo|\tBase type for storing time zone information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Between String and Datetime\n",
    "You can format datetime objects and pandas Timestamp objects, which I’ll introduce later, as strings using str or the strftime method, passing a format specification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 11.2: datetime format specification (ISO C89 compatible)\n",
    "Type\t|Description\n",
    "|:-----|:---------------------------------------------------------------|\n",
    "%Y|\tFour-digit year\n",
    "%y|\tTwo-digit year\n",
    "%m|\tTwo-digit month [01, 12]\n",
    "%d|\tTwo-digit day [01, 31]\n",
    "%H|\tHour (24-hour clock) [00, 23]\n",
    "%I|\tHour (12-hour clock) [01, 12]\n",
    "%M|\tTwo-digit minute [00, 59]\n",
    "%S|\tSecond [00, 61] (seconds 60, 61 account for leap seconds)\n",
    "%f|\tMicrosecond as an integer, zero-padded (from 000000 to 999999)\n",
    "%j|\tDay of the year as a zero-padded integer (from 001 to 336)\n",
    "%w|\tWeekday as an integer [0 (Sunday), 6]\n",
    "%u|\tWeekday as an integer starting from 1, where 1 is Monday.\n",
    "%U|\tWeek number of the year [00, 53]; Sunday is considered the first day of the week, and days before the first Sunday of the year are “week 0”\n",
    "%W|\tWeek number of the year [00, 53]; Monday is considered the first day of the week, and days before the first Monday of the year are “week 0”\n",
    "%z|\tUTC time zone offset as +HHMM or -HHMM; empty if time zone naive\n",
    "%Z|\tTime zone name as a string, or empty string if no time zone\n",
    "%F|\tShortcut for %Y-%m-%d (e.g., 2012-4-18)\n",
    "%D|\tShortcut for %m/%d/%y (e.g., 04/18/12)\n",
    "\n",
    "You can use many of the same format codes to convert strings to dates using `datetime.strptime` (but some codes, like %F, cannot be used):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp = datetime(2011, 1, 3)\n",
    "str(stamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value = \"2011-01-03\"\n",
    "datetime.strptime(value, \"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas.to_datetime method parses many different kinds of date representations. Standard date formats like ISO 8601 can be parsed quickly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datestrs = [\"2011-07-06 12:00:00\", \"2011-08-06 00:00:00\"]\n",
    "pd.to_datetime(datestrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also handles values that should be considered missing (None, empty string, etc.): `NaT` (Not a Time) is pandas’s null value for timestamp data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idx = pd.to_datetime(datestrs + [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "`dateutil.parser` is a useful but imperfect tool. Notably, it will recognize some strings as dates that you might prefer that it didn’t; for example, \"42\" will be parsed as the year 2042 with today’s calendar date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datetime objects also have a number of locale-specific formatting options for systems in other countries or languages. For example, the abbreviated month names will be different on German or French systems compared with English systems. See Table 11.3 for a listing.\n",
    "\n",
    "Table 11.3: Locale-specific date formatting\n",
    "\n",
    "Type\t|Description\n",
    "|:------|:--------------------------------------------------|\n",
    "%a\t|Abbreviated weekday name\n",
    "%A\t|Full weekday name\n",
    "%b\t|Abbreviated month name\n",
    "%B\t|Full month name\n",
    "%c\t|Full date and time (e.g., ‘Tue 01 May 2012 04:20:57 PM’)\n",
    "%p\t|Locale equivalent of AM or PM\n",
    "%x\t|Locale-appropriate formatted date (e.g., in the United States, May 1, 2012 yields ‘05/01/2012’)\n",
    "%X\t|Locale-appropriate time (e.g., ‘04:24:12 PM’)\n",
    "\n",
    "# 11.2 Time Series Basics\n",
    "A basic kind of time series object in pandas is a Series indexed by timestamps, which is often represented outside of pandas as Python strings or datetime objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n",
    "         datetime(2011, 1, 7), datetime(2011, 1, 8),\n",
    "         datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "ts = pd.Series(np.random.standard_normal(6), index=dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other Series, arithmetic operations between differently indexed time series automatically align on the dates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts + ts[::2] # note the data are aligned by date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas stores timestamps using NumPy’s datetime64 data type at the nanosecond resolution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalar values from a DatetimeIndex are pandas `Timestamp` objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pandas.Timestamp` can be substituted most places where you would use a `datetime` object. The reverse is not true, however, because `pandas.Timestamp` can store nanosecond precision data, while datetime stores only up to microseconds. Additionally, `pandas.Timestamp` can store frequency information (if any) and understands how to do time zone conversions and other kinds of manipulations. More on both of these things later in Time Zone Handling.\n",
    "\n",
    "### Indexing, Selection, Subsetting\n",
    "Time series behaves like any other Series when you are indexing and selecting data based on the label:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience, you can also pass a string that is interpretable as a date:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts[\"2011-01-10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longer_ts = pd.Series(np.random.standard_normal(1000),\n",
    "                      index=pd.date_range(\"2000-01-01\", periods=1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longer_ts[\"2001\"] # data of the year 2001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longer_ts[\"2001-05\"] # data of year 2001 and the 5th month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing with datetime objects works as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts[datetime(2011, 1, 7):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts[datetime(2011, 1, 7):datetime(2011, 1, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because most time series data is ordered chronologically, you can slice with timestamps not contained in a time series to perform a range query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ts[\"2011-01-06\":\"2011-01-11\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, you can pass a string date, datetime, or timestamp. Remember that slicing in this manner produces views on the source time series, like slicing NumPy arrays. This means that no data is copied, and modifications on the slice will be reflected in the original data.\n",
    "\n",
    "There is an equivalent instance method, `truncate`, that slices a Series between two dates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.truncate(after=\"2011-01-09\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this holds true for DataFrame as well, indexing on its rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.date_range(\"2000-01-01\", periods=100, freq=\"W-WED\")\n",
    "long_df = pd.DataFrame(np.random.standard_normal((100, 4)),\n",
    "                       index=dates,\n",
    "                       columns=[\"Colorado\", \"Texas\",\n",
    "                                \"New York\", \"Ohio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "long_df.loc[\"2001-05\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series with Duplicate Indices\n",
    "In some applications, there may be multiple data observations falling on a particular timestamp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.DatetimeIndex([\"2000-01-01\", \"2000-01-02\", \"2000-01-02\",\n",
    "                          \"2000-01-02\", \"2000-01-03\"])\n",
    "dup_ts = pd.Series(np.arange(5), index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dup_ts.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to aggregate the data having nonunique timestamps. One way to do this is to use `groupby` and pass `level=0` (the one and only level):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped = dup_ts.groupby(level=0)\n",
    "grouped.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.3 Date Ranges, Frequencies, and Shifting\n",
    "Generic time series in pandas are assumed to be irregular; that is, they have no fixed frequency. For example, you can convert the sample time series to fixed daily frequency by calling resample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampler = ts.resample(\"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Date Ranges\n",
    "`pandas.date_range` is responsible for generating a `DatetimeIndex` with an indicated length according to a particular frequency:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index = pd.date_range(\"2012-04-01\", \"2012-06-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `pandas.date_range` generates daily timestamps. If you pass only a start or end date, you must pass a number of `periods` to generate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(start=\"2012-04-01\", periods=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(end=\"2012-06-01\", periods=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `start` and `end` dates define strict boundaries for the generated date index. For example, if you wanted a date index containing the last business day of each month, you would pass the `\"BM\"` frequency (business end of month; see a more complete listing of frequencies in Table 11.4), and only dates falling on or inside the date interval will be included:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2000-01-01\", \"2000-12-01\", freq=\"BM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 11.4: Base time series frequencies (not comprehensive)\n",
    "Alias\t|Offset type\t|Description\n",
    "|:----------|:--------|:-----------------------------------------------------|\n",
    "D|\tDay|\tCalendar daily\n",
    "B|\tBusinessDay|\tBusiness daily\n",
    "H|\tHour|\tHourly\n",
    "T or min|\tMinute|\tOnce a minute\n",
    "S\t|Second|\tOnce a second\n",
    "L or ms|\tMilli|\tMillisecond (1/1,000 of 1 second)\n",
    "U\t|Micro\t|Microsecond (1/1,000,000 of 1 second)\n",
    "M\t|MonthEnd|\tLast calendar day of month\n",
    "BM\t|BusinessMonthEnd|\tLast business day (weekday) of month\n",
    "MS|\tMonthBegin|\tFirst calendar day of month\n",
    "BMS\t|BusinessMonthBegin|\tFirst weekday of month\n",
    "W-MON, W-TUE, ...|\tWeek|\tWeekly on given day of week (MON, TUE, WED, THU, FRI, SAT, or SUN)\n",
    "WOM-1MON, WOM-2MON, ...\t|WeekOfMonth|\tGenerate weekly dates in the first, second, third, or fourth week of the month (e.g., WOM-3FRI for the third Friday of each month)\n",
    "Q-JAN, Q-FEB, ...|\tQuarterEnd|\tQuarterly dates anchored on last calendar day of each month, for year ending in indicated month (JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC)\n",
    "BQ-JAN, BQ-FEB, ...\t|BusinessQuarterEnd|\tQuarterly dates anchored on last weekday day of each month, for year ending in indicated month\n",
    "QS-JAN, QS-FEB, ...\t|QuarterBegin|\tQuarterly dates anchored on first calendar day of each month, for year ending in indicated month\n",
    "BQS-JAN, BQS-FEB, ...\t|BusinessQuarterBegin|\tQuarterly dates anchored on first weekday day of each month, for year ending in indicated month\n",
    "A-JAN, A-FEB, ...\t|YearEnd|\tAnnual dates anchored on last calendar day of given month (JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, or DEC)\n",
    "BA-JAN, BA-FEB, ...|\tBusinessYearEnd|\tAnnual dates anchored on last weekday of given month\n",
    "AS-JAN, AS-FEB, ...\t|YearBegin|\tAnnual dates anchored on first day of given month\n",
    "BAS-JAN, BAS-FEB, ...\t|BusinessYearBegin|\tAnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.date_range` by default preserves the time (if any) of the start or end timestamp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2012-05-02 12:56:31\", periods=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you will have start or end dates with time information but want to generate a set of timestamps normalized to midnight as a convention. To do this, there is a `normalize` option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2012-05-02 12:56:31\", periods=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequencies and Date Offsets\n",
    "Frequencies in pandas are composed of a base frequency and a multiplier. Base frequencies are typically referred to by a string alias, like \"M\" for monthly or \"H\" for hourly. For each base frequency, there is an object referred to as a date offset. For example, hourly frequency can be represented with the Hour class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pandas.tseries.offsets import Hour, Minute\n",
    "hour = Hour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define a multiple of an offset by passing an integer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "four_hours = Hour(4) # <4*Hours>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most applications, you would never need to explicitly create one of these objects; instead you'd use a string alias like `\"H\"` or `\"4H\"`. Putting an integer before the base frequency creates a multiple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2000-01-01\", \"2000-01-03 23:59\", freq=\"4H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hour(2) + Minute(30)  # <150 * Minutes>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can pass frequency strings, like \"1h30min\", that will effectively be parsed to the same expression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2000-01-01\", periods=10, freq=\"1h30min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some frequencies describe points in time that are not evenly spaced. For example, \"M\" (calendar month end) and \"BM\" (last business/weekday of month) depend on the number of days in a month and, in the latter case, whether the month ends on a weekend or not. We refer to these as `anchored offsets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week of month dates\n",
    "One useful frequency class is “week of month,” starting with WOM. This enables you to get dates like the third Friday of each month:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "monthly_dates = pd.date_range(\"2012-01-01\", \"2012-09-01\", freq=\"WOM-3FRI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting (Leading and Lagging) Data\n",
    "Shifting refers to moving data backward and forward through time. Both Series and DataFrame have a shift method for doing naive shifts forward or backward, leaving the index unmodified:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts = pd.Series(np.random.standard_normal(4),\n",
    "               index=pd.date_range(\"2000-01-01\", periods=4, freq=\"M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.shift(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.shift(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use of shift is computing consecutive percent changes in a time series or multiple time series as DataFrame columns. This is expressed as:\n",
    "\n",
    "`ts / ts.shift(1) - 1`\n",
    "\n",
    "Because naive shifts leave the index unmodified, some data is discarded. Thus if the frequency is known, it can be passed to shift to advance the timestamps instead of simply the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.shift(2, freq=\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.shift(1, freq=\"D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.shift(1, freq=\"90T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `T` here stands for minutes. Note that the freq parameter here indicates the offset to apply to the timestamps, but it does not change the underlying frequency of the data, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting dates with offsets\n",
    "The pandas date offsets can also be used with `datetime` or `Timestamp` objects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "now = datetime(2011, 11, 17)\n",
    "now + 3 * Day()  # Timestamp('2011-11-20 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add an `anchored` offset like `MonthEnd`, the first increment will \"roll forward\" a date to the next date according to the frequency rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now + MonthEnd() # Timestamp('2011-11-30 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now + MonthEnd(2) # Timestamp('2011-12-31 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchored offsets can explicitly “roll” dates forward or backward by simply using their `rollforward` and `rollback` methods, respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offset = MonthEnd()\n",
    "offset.rollforward(now) #Timestamp('2011-11-30 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offset.rollback(now) # previous month end Timestamp('2011-10-31 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A creative use of date offsets is to use these methods with `groupby`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.groupby(MonthEnd().rollforward).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts[\"2000-03\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, an easier and faster way to do this is with `resample` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"M\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 Time Zone Handling\n",
    "Working with time zones can be one of the most unpleasant parts of time series manipulation. As a result, many time series users choose to work with time series in coordinated universal time or UTC, which is the geography-independent international standard. Time zones are expressed as offsets from UTC; for example, New York is four hours behind UTC during daylight saving time (DST) and five hours behind the rest of the year.\n",
    "\n",
    "In Python, time zone information comes from the third-party `pytz` library (installable with pip or conda), which exposes the Olson database, a compilation of world time zone information. This is especially important for historical data because the DST transition dates (and even UTC offsets) have been changed numerous times depending on the regional laws. In the United States, the DST transition times have been changed many times since 1900!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pytz\n",
    "pytz.common_timezones[-5:] # ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a time zone object from `pytz`, use `pytz.timezone`: Methods in pandas will accept either time zone names or these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tz = pytz.timezone(\"America/New_York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Zone Localization and Conversion\n",
    "By default, time series in pandas are `time zone naive` (no time zone). For example, consider the following time series:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(ts.index.tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date ranges can be generated with a time zone set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range(\"2012-03-09 09:30\", periods=10, tz=\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion from naive to localized (reinterpreted as having been observed in a particular time zone) is handled by the `tz_localize` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_utc = ts.tz_localize(\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_utc.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a time series has been localized to a particular time zone, it can be converted to another time zone with `tz_convert`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_utc.tz_convert(\"America/New_York\")# note the -5 and -4(DST): offset from UTC time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts_eastern.tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tz_localize` and `tz_convert` are also instance methods on DatetimeIndex:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with Time Zone-Aware Timestamp Objects\n",
    "Similar to time series and date ranges, individual Timestamp objects similarly can be localized from naive to time zone-aware and converted from one time zone to another:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a time zone when creating the Timestamp:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp_moscow = pd.Timestamp(\"2011-03-12 04:00\", tz=\"Europe/Moscow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time zone-aware Timestamp objects internally store a UTC timestamp value as nanoseconds since the Unix epoch (January 1, 1970), so changing the time zone does not alter the internal UTC value:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp_utc.value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp_utc.tz_convert(\"America/New_York\").value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing time arithmetic using pandas’s DateOffset objects, pandas respects daylight saving time transitions where possible. Here we construct timestamps that occur right before DST transitions (forward and backward). First, 30 minutes before transitioning to DST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp = pd.Timestamp(\"2012-03-11 01:30\", tz=\"US/Eastern\") # 30 minutes before the DST transition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp + Hour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, 90 minutes before transitioning out of DST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp = pd.Timestamp(\"2012-11-04 00:30\", tz=\"US/Eastern\") # 90 mins before transition out of DST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stamp + 2 * Hour()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations Between Different Time Zones\n",
    "If two time series with different time zones are combined, the result will be UTC. Since the timestamps are stored under the hood in UTC, this is a straightforward operation and requires no conversion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.date_range(\"2012-03-07 09:30\", periods=10, freq=\"B\")\n",
    "ts = pd.Series(np.random.standard_normal(len(dates)), index=dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts1 = ts[:7].tz_localize(\"Europe/London\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts2 = ts1[2:].tz_convert(\"Europe/Moscow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = ts1 + ts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between time zone-naive and time zone-aware data are not supported and will raise an exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 Periods and Period Arithmetic\n",
    "Periods represent time spans, like days, months, quarters, or years. The `pandas.Period` class represents this data type, requiring a string or integer and a supported frequency from Table 11.4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = pd.Period(\"2011\", freq=\"A-DEC\") # the entire year 2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the Period object represents the full time span from January 1, 2011, to December 31, 2011, inclusive. Conveniently, adding and subtracting integers from periods has the effect of shifting their frequency:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p + 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two periods have the same frequency, their difference is the number of units between them as a date offset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.Period(\"2014\", freq=\"A-DEC\") - p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular ranges of periods can be constructed with the period_range function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "periods = pd.period_range(\"2000-01-01\", \"2000-06-30\", freq=\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PeriodIndex` class stores a sequence of periods and can serve as an axis index in any pandas data structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.Series(np.random.standard_normal(6), index=periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an array of strings, you can also use the `PeriodIndex` class, where all of its values are periods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "values = [\"2001Q3\", \"2002Q2\", \"2003Q1\"]\n",
    "index = pd.PeriodIndex(values, freq=\"Q-DEC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period Frequency Conversion\n",
    "Periods and PeriodIndex objects can be converted to another frequency with their `asfreq` method. As an example, suppose we had an annual period and wanted to convert it into a monthly period either at the start or end of the year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = pd.Period(\"2011\", freq=\"A-DEC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p+1 # note p+1 is 2012 because the the frequency is by year ending in dec. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm=p.asfreq(\"M\", how=\"start\")# the  period is converted to monthly frequency. count each period  from the first (start) month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmd =  p.asfreq(\"M\", how=\"end\")  # count each period (1 year) from the end month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.asfreq(\"M\") # same as p.asfreq(\"M\", how=\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of `Period(\"2011\", \"A-DEC\")` as being a sort of cursor pointing to a span of time, subdivided by monthly periods.  For a fiscal year ending on a month other than December, the corresponding monthly subperiods are different:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = pd.Period(\"2011\", freq=\"A-JUN\") # the period 2011 ends in Jun. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmj=p.asfreq(\"M\", how=\"start\") # use (fiscal) year as frequency, but each fiscal year starts in July. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pme=p.asfreq(\"M\", how=\"end\") # the (fiscal) year ends in 2011-06. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are converting from high to low frequency, pandas determines the subperiod, depending on where the superperiod “belongs.” For example, in A-JUN frequency, the month Aug-2011 is actually part of the 2012 period:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = pd.Period(\"Aug-2011\", \"M\") #higher freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pma = p.asfreq(\"A-JUN\") # lower frequency: converted to annum freq, but each year ends in June. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole PeriodIndex objects or time series can be similarly converted with the same semantics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "periods = pd.period_range(\"2006\", \"2009\", freq=\"A-DEC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts = pd.Series(np.random.standard_normal(len(periods)), index=periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.asfreq(\"M\", how=\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.asfreq(\"B\", how=\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quarterly Period Frequencies\n",
    "Quarterly data is standard in accounting, finance, and other fields. Much quarterly data is reported relative to a fiscal year end, typically the last calendar or business day of one of the 12 months of the year. Thus, the period 2012Q4 has a different meaning depending on fiscal year end. pandas supports all 12 possible quarterly frequencies as Q-JAN through Q-DEC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = pd.Period(\"2012Q4\", freq=\"Q-JAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.asfreq(\"D\", how=\"start\") #converted to daily frequency: \n",
    "#the start day of 2012Q4 with the last Quarter ending in Jan is 2011-11-01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.asfreq(\"D\", how=\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it’s possible to do convenient period arithmetic; for example, to get the timestamp at 4 P.M. on the second-to-last business day of the quarter, you could do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p.asfreq(\"B\", how=\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(p.asfreq(\"B\", how=\"end\") - 1).asfreq(\"T\", how=\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4pm = (p.asfreq(\"B\", how=\"end\") - 1).asfreq(\"T\", how=\"start\") + 16 * 60 # T for minute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p4pm.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_timestamp` method returns the Timestamp at the start of the period by default.\n",
    "\n",
    "You can generate quarterly ranges using `pandas.period_range`. The arithmetic is identical, too:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "periods = pd.period_range(\"2011Q3\", \"2012Q4\", freq=\"Q-JAN\")\n",
    "ts = pd.Series(np.arange(len(periods)), index=periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_periods = (periods.asfreq(\"B\", \"end\") - 1).asfreq(\"H\", \"start\") + 16\n",
    "ts.index = new_periods.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Timestamps to Periods (and Back)\n",
    "Series and DataFrame objects indexed by timestamps can be converted to periods with the to_period method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.date_range(\"2000-01-01\", periods=3, freq=\"M\")\n",
    "ts = pd.Series(np.random.standard_normal(3), index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pts = ts.to_period()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since periods refer to nonoverlapping time spans, a timestamp can only belong to a single period for a given frequency. While the frequency of the new PeriodIndex is inferred from the timestamps by default, you can specify any supported frequency (most of those listed in Table 11.4 are supported). There is also no problem with having duplicate periods in the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts2.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert back to timestamps, use the `to_timestamp` method, which returns a DatetimeIndex:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pts = ts2.to_period() #default freq=D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pts.to_timestamp(how=\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a PeriodIndex from Arrays\n",
    "Fixed frequency datasets are sometimes stored with time span information spread across multiple columns. For example, in this macroeconomic dataset, the year and quarter are in different columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing these arrays to PeriodIndex with a frequency, you can combine them to form an index for the DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index = pd.PeriodIndex(year=data[\"year\"], quarter=data[\"quarter\"],\n",
    "                       freq=\"Q-DEC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 Resampling and Frequency Conversion\n",
    "Resampling refers to the process of converting a time series from one frequency to another. Aggregating higher frequency data to lower frequency is called downsampling, while converting lower frequency to higher frequency is called upsampling. Not all resampling falls into either of these categories; for example, converting W-WED (weekly on Wednesday) to W-FRI is neither upsampling nor downsampling.\n",
    "\n",
    "pandas objects are equipped with a resample method, which is the workhorse function for all frequency conversion. resample has a similar API to groupby; you call resample to group the data, then call an aggregation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.date_range(\"2000-01-01\", periods=100)\n",
    "ts = pd.Series(np.random.standard_normal(len(dates)), index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"M\").mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"M\", kind=\"period\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 11.5: resample method arguments\n",
    "\n",
    "Argument\t|Description\n",
    "|:------------|:--------------------------------------------------------------------------|\n",
    "rule|\tString, DateOffset, or timedelta indicating desired resampled frequency (for example, ’M', ’5min', or Second(15))\n",
    "axis|\tAxis to resample on; default axis=0\n",
    "fill_method\t|How to interpolate when upsampling, as in \"ffill\" or \"bfill\"; by default does no interpolation\n",
    "closed\t|In downsampling, which end of each interval is closed (inclusive), \"right\" or \"left\"\n",
    "label|\tIn downsampling, how to label the aggregated result, with the \"right\" or \"left\" bin edge (e.g., the 9:30 to 9:35 five-minute interval could be labeled 9:30 or 9:35)\n",
    "limit|\tWhen forward or backward filling, the maximum number of periods to fill\n",
    "kind|\tAggregate to periods (\"period\") or timestamps (\"timestamp\"); defaults to the type of index the time series has\n",
    "convention|\tWhen resampling periods, the convention (\"start\" or \"end\") for converting the low-frequency period to high frequency; defaults to \"start\"\n",
    "origin|\tThe \"base\" timestamp from which to determine the resampling bin edges; can also be one of \"epoch\", \"start\", \"start_day\", \"end\", or \"end_day\"; see the resample docstring for full details\n",
    "offset|\tAn offset timedelta added to the origin; defaults to None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling\n",
    "Downsampling is aggregating data to a regular, lower frequency. The data you’re aggregating doesn’t need to be fixed frequently; the desired frequency defines bin edges that are used to slice the time series into pieces to aggregate. For example, to convert to monthly, \"M\" or \"BM\", you need to chop up the data into one-month intervals. Each interval is said to be half-open; a data point can belong only to one interval, and the union of the intervals must make up the whole time frame. There are a couple things to think about when using resample to downsample data:\n",
    "\n",
    "Which side of each interval is closed\n",
    "\n",
    "How to label each aggregated bin, either with the start of the interval or the end\n",
    "\n",
    "To illustrate, let’s look at some one-minute frequency data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dates = pd.date_range(\"2000-01-01\", periods=12, freq=\"T\") # T for min\n",
    "ts = pd.Series(np.arange(len(dates)), index=dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"5min\").sum() #default: left-inclusive; use teh start time to denote each period\n",
    "#each bin is labeled by the timestamps of the left side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"5min\", closed=\"right\").sum() #each bin is labeled by the left edge\n",
    "# first timestamp belons to the previous period, because it doesnot belongs to (left_0, right_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"5min\", closed=\"right\", label=\"right\").sum()#label by right edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, you might want to shift the result index by some amount, say subtracting one second from the right edge to make it more clear which interval the timestamp refers to. To do this, add an offset to the resulting index:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pandas.tseries.frequencies import to_offset\n",
    "result = ts.resample(\"5min\", closed=\"right\", label=\"right\").sum()\n",
    "result.index = result.index + to_offset(\"-1s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-high-low-close (OHLC) resampling\n",
    "In finance, a popular way to aggregate a time series is to compute four values for each bucket: the first (open), last (close), maximum (high), and minimal (low) values. By using the ohlc aggregate function, you will obtain a DataFrame having columns containing these four aggregates, which are efficiently computed in a single function call:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts.resample(\"5min\").ohlc() # for each bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling and Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are using an aggregation function with this data, there is only one value per group, and missing values result in the gaps. We use the `asfreq` method to convert to the higher frequency without any aggregation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_daily = frame.resample(\"D\").asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to fill forward each weekly value on the non-Wednesdays. The same filling or interpolation methods available in the fillna and reindex methods are available for resampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frame.resample(\"D\").ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frame.resample(\"D\").ffill(limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, the new date index need not coincide with the old one at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frame.resample(\"W-THU\").ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling with Periods\n",
    "Resampling data indexed by periods is similar to timestamps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annual_frame = frame.resample(\"A-DEC\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling is more nuanced, as before resampling you must make a decision about which end of the time span in the new frequency to place the values. The convention argument defaults to \"start\" but can also be \"end\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since periods refer to time spans, the rules about upsampling and downsampling are more rigid:\n",
    "\n",
    "In downsampling, the target frequency must be a subperiod of the source frequency.\n",
    "\n",
    "In upsampling, the target frequency must be a superperiod of the source frequency.\n",
    "\n",
    "If these rules are not satisfied, an exception will be raised. This mainly affects the quarterly, annual, and weekly frequencies; for example, the time spans defined by Q-MAR only line up with A-MAR, A-JUN, A-SEP, and A-DEC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annual_frame.resample(\"Q-MAR\").asfreq() #default: Place the value at the start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annual_frame.resample(\"Q-MAR\").ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped Time Resampling\n",
    "For time series data, the resample method is semantically a group operation based on a time intervalization. Here's a small example table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.set_index(\"time\").resample(\"5min\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that a DataFrame contains multiple time series, marked by an additional group key column:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "repeated_array = np.tile(A, (2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 = pd.DataFrame({\"time\": times.repeat(3),\n",
    "                    \"key\": np.tile([\"a\", \"b\", \"c\"], N),\n",
    "                    \"value\": np.arange(N * 3.)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same resampling for each value of \"key\", we introduce the `pandas.Grouper` object: One constraint with using `pandas.Grouper` is that the time must be the index of the Series or DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_key = pd.Grouper(freq=\"5min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set the time index, group by `\"key\"` and `time_key`, and aggregate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampled = (df2.set_index(\"time\") #time must be the index to use pd.Grouper\n",
    "             .groupby([\"key\", time_key])\n",
    "             .sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampled.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.7 Moving Window Functions\n",
    "An important class of array transformations used for time series operations are statistics and other functions evaluated over a sliding window or with exponentially decaying weights. This can be useful for smoothing noisy or gappy data. I call these moving window functions, even though they include functions without a fixed-length window like exponentially weighted moving average. Like other statistical functions, these also automatically exclude missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px_1.isna().sum()# number of na rows (added dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px_1[close_px_1.isna().any(axis=1)] # list all dates with nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px = close_px.resample(\"B\").ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now introduce the `rolling` operator, which behaves similarly to `resample` and `groupby`. It can be called on a Series or DataFrame along with a window (expressed as a number of periods; see Apple price with 250-day moving average for the plot created):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px[\"AAPL\"].rolling(250).mean() # note the first 249 values are nana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px[\"AAPL\"].rolling(250).mean().isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px[\"AAPL\"].plot()\n",
    "close_px[\"AAPL\"].rolling(250).mean().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `rolling(250)` is similar in behavior to groupby, but instead of grouping, it creates an object that enables grouping over a 250-day sliding window. So here we have the 250-day moving window average of Apple's stock price.\n",
    "\n",
    "By default, `rolling` functions require all of the values in the window to be `non-NA`. This behavior can be changed to account for missing data and, in particular, the fact that you will have fewer than window periods of data at the beginning of the time series (see Apple 250-day daily return standard deviation):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px_all[\"AAPL\"].resample('B').asfreq().isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "close_px_all[\"AAPL\"].resample('B').asfreq().rolling(250).mean().plot() # with na values, no mean will be computeed. \n",
    "# if reaplce mean() by mean(skipna=True) still not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px[\"AAPL\"].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std250 = close_px[\"AAPL\"].pct_change().rolling(250, min_periods=10).std()\n",
    "std250[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute an expanding window mean, use the `expanding` operator instead of `rolling`. The expanding mean starts the time window from the same point as the rolling window and increases the size of the window until it encompasses the whole series. An expanding window mean on the std250 time series looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expanding_mean = std250.expanding().mean() \n",
    "#expanding(min_periods=1,  axis=0)\n",
    "#example ts.expanding().sum(): computer cumulative sum of ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a moving window function on a DataFrame applies the transformation to each column (see Stock prices 60-day moving average (log y-axis)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.style.use('grayscale')\n",
    "close_px.rolling(60).mean().plot(logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rolling` function also accepts a string indicating a fixed-size time offset rolling() in moving window functions rather than a set number of periods. Using this notation can be useful for irregular time series. These are the same strings that you can pass to resample. For example, we could compute a 20-day rolling mean like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close_px.rolling(\"20D\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponentially Weighted Functions\n",
    "An alternative to using a fixed window size with equally weighted observations is to specify a constant decay factor to give more weight to more recent observations. There are a couple of ways to specify the decay factor. A popular one is using a span, which makes the result comparable to a simple moving window function with window size equal to the span.\n",
    "\n",
    "Since an exponentially weighted statistic places more weight on more recent observations, it “adapts” faster to changes compared with the equal-weighted version.\n",
    "\n",
    "`pandas` has the `ewm` operator (which stands for exponentially weighted moving) to go along with `rolling` and `expanding`. Here’s an example comparing a 30-day moving average of Apple’s stock price with an exponentially weighted (EW) moving average with `span=60` (see Simple moving average versus exponentially weighted):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "aapl_px = close_px[\"AAPL\"][\"2006\":\"2007\"]\n",
    "\n",
    "ma30 = aapl_px.rolling(30, min_periods=20).mean()\n",
    "ewma30 = aapl_px.ewm(span=30).mean()\n",
    "\n",
    "aapl_px.plot(style=\"k-\", label=\"Price\")\n",
    "ma30.plot(style=\"k--\", label=\"Simple Moving Avg\")\n",
    "ewma30.plot(style=\"k-\", label=\"EW MA\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Moving Window Functions\n",
    "Some statistical operators, like correlation and covariance, need to operate on two time series. As an example, financial analysts are often interested in a stock’s correlation to a benchmark index like the S&P 500. To have a look at this, we first compute the percent change for all of our time series of interest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we call `rolling`, the `corr` aggregation function can then compute the rolling correlation with spx_rets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr = returns[\"AAPL\"].rolling(125, min_periods=100).corr(spx_rets)\n",
    "corr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to compute the rolling correlation of the S&P 500 index with many stocks at once.  we can compute all of the rolling correlations in one shot by calling rolling on the DataFrame and passing the spx_rets Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "corr = returns.rolling(125, min_periods=100).corr(spx_rets)\n",
    "corr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Defined Moving Window Functions\n",
    "The `apply` method on rolling and related methods provides a way to apply an array function of your own creation over a moving window. The only requirement is that the function produce a single value (a reduction) from each piece of the array. For example, while we can compute sample quantiles using `rolling(...).quantile(q)`, we might be interested in the percentile rank of a particular value over the sample. The `scipy.stats.percentileofscore` function does just this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import percentileofscore\n",
    "def score_at_2percent(x):\n",
    "    return percentileofscore(x, 0.02) #compute the 2% percentile value in x. \n",
    "\n",
    "result = returns[\"AAPL\"].rolling(250).apply(score_at_2percent)\n",
    "result.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
