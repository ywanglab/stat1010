{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10  Data Aggregation and Group Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 How to Think About Group Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`split-apply-combine`\n",
    "\n",
    " 1. data contained in a pandas object, whether a Series, DataFrame, or otherwise, is split into groups based on one or more keys. The splitting is performed on a particular axis of an object. For example, a DataFrame can be grouped on its rows (`axis=\"index\"`) or its columns (`axis=\"columns\"`). \n",
    "    Each grouping key can take many forms:\n",
    "\n",
    "        - A list or array of values that is the same length as the axis being grouped\n",
    "\n",
    "        - A value indicating a column name in a DataFrame\n",
    "\n",
    "        - A dictionary or Series giving a correspondence between the values on the axis being grouped and the group names\n",
    "\n",
    "        - A function to be invoked on the axis index or the individual labels in the index\n",
    " \n",
    " 2. Once this is done, a function is applied to each group, producing a new value. \n",
    " 3. Finally, the results of all those function applications are combined into a result object. The form of the resulting object will usually depend on what’s being done to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"data1\"].groupby(df[\"key1\"]).mean() # note \"key1\" becomes the index name of the prouped.mean series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"data1\"].groupby([df[\"key1\"], df[\"key2\"]]).mean() # Use two keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys are provided by lists\n",
    "states = np.array([\"OH\", \"CA\", \"CA\", \"OH\", \"OH\", \"CA\", \"OH\"])\n",
    "years = [2005, 2005, 2006, 2005, 2006, 2005, 2006]\n",
    "df[\"data1\"].groupby([states, years]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, the grouping information is found in the same DataFrame as the data you want to work on. In that case, you can pass column names (whether those are strings, numbers, or other Python objects) as the group keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.groupby(\"key1\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.groupby(\"key2\").mean(numeric_only=True) # because 'key1` col is not numeric, can not aggregated with mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple keys provided by a list of col names\n",
    "df.groupby([\"key1\", \"key2\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of the objective in using groupby, a generally useful GroupBy method is `size`, which returns a Series containing ***group sizes***:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.groupby([\"key1\", \"key2\"]).size() # default drop na values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not drop na values\n",
    "df.groupby(\"key1\", dropna=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.groupby(\"key1\").count() # non-null values in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over Groups\n",
    "The object returned by groupby supports iteration, generating a sequence of 2-tuples containing the group name along with the chunk of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for name, group in df.groupby(\"key1\"): # name is different value of key1, and group is each group member\n",
    "    print('-'*20)\n",
    "    print(name)\n",
    "    print('-'*20)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (k1, k2), group in df.groupby([\"key1\", \"key2\"]):\n",
    "    print('-'*20)\n",
    "    print((k1, k2))\n",
    "    print('-'*20)\n",
    "    print(group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recipe you may find useful is computing a dictionary of the data pieces as a one-liner:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pieces = {name: group for name, group in df.groupby(\"key1\")}\n",
    "pieces[\"b\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default groupby groups on `axis=\"index\"`, but you can group on any of the other axes. For example, we could group the columns of our example df here by whether they start with \"key\" or \"data\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped = df.groupby({\"key1\": \"key\", \"key2\": \"key\", # note the groupping keys are passed with a dictionary\n",
    "                      \"data1\": \"data\", \"data2\": \"data\"}, axis=\"columns\") \n",
    "#equivalent to\n",
    "#grouped = df.groupby(['key', 'key', 'data','data'], axis=\"columns\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for group_key, group_values in grouped:\n",
    "    \n",
    "    print('-'*30)\n",
    "    print(group_key)\n",
    "    print('-'*30)\n",
    "    print(group_values)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Column or Subset of Columns\n",
    "Indexing a GroupBy object created from a DataFrame with a column name or array of column names has the effect of column subsetting for aggregation. This means that\n",
    "```\n",
    "df.groupby(\"key1\")[\"data1\"]  # SeriesGroupBy obj\n",
    "df.groupby(\"key1\")[[\"data2\"]] #DataframeGoupBy obj\n",
    "```\n",
    "are conveniences for:\n",
    "```\n",
    "df[\"data1\"].groupby(df[\"key1\"]) # note the group_by key needs to be a series. \n",
    "df[[\"data2\"]].groupby(df[\"key1\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with Dictionaries and Series\n",
    "Grouping information may exist in a form other than an array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping = {\"a\": \"red\", \"b\": \"red\", \"c\": \"blue\",\n",
    "           \"d\": \"blue\", \"e\": \"red\", \"f\" : \"orange\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by_column = people.groupby(mapping, axis=\"columns\") #unused key 'f' is ok. \n",
    "by_column.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map_series = pd.Series(mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people.groupby(map_series, axis=\"columns\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with Functions\n",
    "Using Python functions is a more generic way of defining a group mapping compared with a dictionary or Series. Any function passed as a group key will be called once per index value (or once per column value if using axis=\"columns\"), with the return values being used as the group names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people.groupby(len).sum() # len applied to index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing functions with arrays, dictionaries, or Series is not a problem, as everything gets converted to arrays internally:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key_list = [\"one\", \"one\", \"one\", \"two\", \"two\"]\n",
    "people.groupby([len, key_list]).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping by Index Levels\n",
    "A final convenience for hierarchically indexed datasets is the ability to aggregate using one of the levels of an axis index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns = pd.MultiIndex.from_arrays([[\"US\", \"US\", \"US\", \"JP\", \"JP\"],\n",
    "                                    [1, 3, 5, 1, 3]],\n",
    "                                    names=[\"cty\", \"tenor\"])\n",
    "hier_df = pd.DataFrame(np.random.standard_normal((4, 5)), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier_df.groupby(level=\"cty\", axis=\"columns\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Data Aggregation\n",
    "Aggregations refer to any data transformation that produces scalar values from arrays. \n",
    "\n",
    "Table 10.1: Optimized groupby methods\n",
    "Function name|\tDescription\n",
    "|:---------------|:-------------------------------------------------------------------|\n",
    "any, all|\tReturn True if any (one or more values) or all non-NA values are \"truthy\"\n",
    "count|\tNumber of non-NA values\n",
    "cummin, cummax\t|Cumulative minimum and maximum of non-NA values\n",
    "cumsum|\tCumulative sum of non-NA values\n",
    "cumprod|\tCumulative product of non-NA values\n",
    "first, last\t|First and last non-NA values\n",
    "mean|\tMean of non-NA values\n",
    "median|\tArithmetic median of non-NA values\n",
    "min, max|\tMinimum and maximum of non-NA values\n",
    "nth|\tRetrieve value that would appear at position n with the data in sorted order\n",
    "ohlc|\tCompute four \"open-high-low-close\" statistics for time series-like data\n",
    "prod|\tProduct of non-NA values\n",
    "quantile|\tCompute sample quantile\n",
    "rank\t|Ordinal ranks of non-NA values, like calling Series.rank\n",
    "size\t|Compute group sizes, returning result as a Series\n",
    "sum\t|Sum of non-NA values\n",
    "std, var|\tSample standard deviation and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use aggregations of your own devising and additionally call any method that is also defined on the object being grouped. For example, the `nsmallest` Series method selects the smallest requested number of values from the data. While `nsmallest` is not explicitly implemented for GroupBy, we can still use it with a nonoptimized implementation. Internally, GroupBy slices up the Series, calls `piece.nsmallest(n)` for each piece, and then assembles those results into the result object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped[\"data1\"].nsmallest(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use your own aggregation functions, pass any function that aggregates an array to the aggregate method or its short alias `agg`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def peak_to_peak(arr):\n",
    "    return arr.max() - arr.min()\n",
    "grouped.agg(peak_to_peak) # the funciton peak_to_peak needs to aggregates an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column-Wise and Multiple Function Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped_pct.agg([\"mean\", \"std\", peak_to_peak]) # aggregate with multiple funcitons\n",
    "# col names are taken from the funciton names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " if you pass a list of `(name, function)` tuples, the first element of each tuple will be used as the DataFrame column names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped_pct.agg([(\"average\", \"mean\"), (\"stdev\", np.std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a DataFrame you have more options, as you can specify a list of functions to apply to all of the columns or different functions per column. \n",
    "\n",
    "A DataFrame will have hierarchical columns only if multiple functions are applied to at least one column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions = [\"count\", \"mean\", \"max\"]\n",
    "result = grouped[[\"tip_pct\", \"total_bill\"]].agg(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, a list of tuples with custom names can be passed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose you wanted to apply potentially different functions to one or more of the columns. To do this, pass a dictionary to agg that contains a mapping of column names to any of the function specifications listed so far:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped.agg({\"tip\" : np.max, \"size\" : \"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "grouped.agg({\"tip_pct\" : [\"min\", \"max\", \"mean\", \"std\"],\n",
    "             \"size\" : \"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning Aggregated Data Without Row Indexes\n",
    "In all of the examples up until now, the aggregated data comes back with an index, potentially hierarchical, composed from the unique group key combinations. Since this isn’t always desirable, you can disable this behavior in most cases by passing `as_index=False` to groupby. \n",
    "\n",
    "Of course, it’s always possible to obtain the result in this format by calling reset_index on the result. Using the `as_index=False` argument avoids some unnecessary computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped = tips.groupby([\"day\", \"smoker\"], as_index=False) # the grouping indices becomes columns\n",
    "grouped.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Apply: General split-apply-combine\n",
    "The most general-purpose GroupBy method is apply, which is the subject of this section. apply splits the object being manipulated into pieces, invokes the passed function on each piece, and then attempts to concatenate the pieces.\n",
    "\n",
    "What occurs inside the function passed is up to you; it must either return a pandas object or a scalar value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.groupby(\"smoker\").apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a function to apply that takes other arguments or keywords, you can pass these after the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.groupby([\"smoker\", \"day\"]).apply(top, n=1, column=\"total_bill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside GroupBy, when you invoke a method like describe, it is actually just a shortcut for:\n",
    "```\n",
    "def f(group):\n",
    "    return group.describe()\n",
    "\n",
    "grouped.apply(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppressing the Group Keys\n",
    "You can disable this by passing `group_keys=False` to groupby:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.groupby(\"smoker\", group_keys=False).apply(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile and Bucket Analysis\n",
    "Combining `pd.cut` and `pd.qcut` with groupby makes it convenient to perform bucket or quantile analysis on a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quartiles = pd.cut(frame[\"data1\"], 4) # or use .qcut\n",
    "quartiles.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Categorical object returned by cut can be passed directly to groupby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_stats(group):\n",
    "    return pd.DataFrame(\n",
    "        {\"min\": group.min(), \"max\": group.max(),\n",
    "        \"count\": group.count(), \"mean\": group.mean()}\n",
    "    )\n",
    "\n",
    "grouped = frame.groupby(quartiles)\n",
    "grouped.apply(get_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind the same result could have been computed more simply with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped.agg([\"min\", \"max\", \"count\", \"mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were equal-length buckets; to compute equal-size buckets based on sample quantiles, use pandas.qcut. We can pass 4 as the number of bucket compute sample quartiles, and pass labels=False to obtain just the quartile indices instead of intervals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Filling Missing Values with Group-Specific Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fill_mean(group):\n",
    "    return group.fillna(group.mean())\n",
    "\n",
    "data.groupby(group_key).apply(fill_mean) # fill na using group means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill_values = {\"East\": 0.5, \"West\": -1}\n",
    "def fill_func(group):\n",
    "    #print(group.name)\n",
    "    return group.fillna(fill_values[group.name]) # group has name attribute\n",
    "\n",
    "data.groupby(group_key).apply(fill_func) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Random Sampling and Permutation\n",
    "There are a number of ways to perform the “draws”; here we use the `sample` method for Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deck.groupby(get_suit, group_keys=False).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Group Weighted Average and Correlation\n",
    "Under the split-apply-combine paradigm of groupby, operations between columns in a DataFrame or two Series, such as a group weighted average, are possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grouped = df.groupby(\"category\")\n",
    "def get_wavg(group):\n",
    "    return np.average(group[\"data\"], weights=group[\"weights\"])\n",
    "\n",
    "grouped.apply(get_wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def spx_corr(group):\n",
    "    return group.corrwith(group[\"SPX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_year(x):\n",
    "    return x.year\n",
    "\n",
    "by_year = rets.groupby(get_year)\n",
    "by_year.apply(spx_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def corr_aapl_msft(group):\n",
    "    return group[\"AAPL\"].corr(group[\"MSFT\"])\n",
    "by_year.apply(corr_aapl_msft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Group-Wise Linear Regression\n",
    "In the same theme as the previous example, you can use groupby to perform more complex group-wise statistical analysis, as long as the function returns a pandas object or scalar value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "def regress(data, yvar=None, xvars=None):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    X[\"intercept\"] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by_year.apply(regress, yvar=\"AAPL\", xvars=[\"SPX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Group Transforms and \"Unwrapped\" GroupBys\n",
    "\n",
    "In Apply: General split-apply-combine, we looked at the apply method in grouped operations for performing transformations. There is another built-in method called transform, which is similar to apply but imposes more constraints on the kind of function you can use:\n",
    "\n",
    "It can produce a scalar value to be broadcast to the shape of the group.\n",
    "\n",
    "It can produce an object of the same shape as the input group.\n",
    "\n",
    "It must not mutate its input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_mean(group):\n",
    "    return group.mean()\n",
    "g.transform(get_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g.transform('mean') # pass a built-in aggregate function \"mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def times_two(group):\n",
    "    return group * 2\n",
    "g.transform(times_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built-in aggregate functions like `'mean'` or `'sum'` are often much faster than a general `apply` function. These also have a \"fast path\" when used with transform. This allows us to perform what is called an unwrapped group operation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g.transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are doing arithmetic between the outputs of multiple GroupBy operations instead of writing a function and passing it to `groupby(...).apply`. That is what is meant by \"unwrapped.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "normalized = (df['value'] - g.transform('mean')) / g.transform('std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Pivot Tables and Cross-Tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pivot table is a data summarization tool frequently found in spreadsheet programs and other data analysis software. It aggregates a table of data by one or more keys, arranging the data in a rectangle with some of the group keys along the rows and some along the columns. Pivot tables in Python with pandas are made possible through the groupby facility described in this chapter, combined with reshape operations utilizing hierarchical indexing. DataFrame also has a `pivot_table` method, and there is also a top-level `pandas.pivot_table` function. In addition to providing a convenience interface to `groupby`, `pivot_table` can add partial totals, also known as `margins`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "tips.pivot_table(index=[\"day\", \"smoker\"],\n",
    "                 values=[\"size\", \"tip\", \"tip_pct\", \"total_bill\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n",
    "                 values=[\"tip_pct\", \"size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could augment this table to include `partial totals` by passing `margins=True`. This has the effect of adding All row and column labels, with corresponding values being the group statistics for all the data within a single tier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n",
    "                 values=[\"tip_pct\", \"size\"],  margins=True) # aggfunc=mean, find means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use an aggregation function other than mean, pass it to the `aggfunc` keyword argument. For example, `\"count\"` or `len` will give you a cross-tabulation (count or frequency) of group sizes (though `\"count\"` will exclude null values from the count within data groups, while `len` will not):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.pivot_table(index=[\"time\", \"day\"], columns=\"smoker\",\n",
    "                 values=[\"tip_pct\", \"size\"], aggfunc=\"count\",  margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tips.pivot_table(index=[\"time\", \"size\", \"smoker\"], columns=\"day\",\n",
    "                 values=\"tip_pct\", fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 10.2: pivot_table options\n",
    "Argument|\tDescription\n",
    "|:------------|:-----------------------------------------------------------------------|\n",
    "values|\tColumn name or names to aggregate; by default, aggregates all numeric columns\n",
    "index|\tColumn names or other group keys to group on the rows of the resulting pivot table\n",
    "columns|\tColumn names or other group keys to group on the columns of the resulting pivot table\n",
    "aggfunc|\tAggregation function or list of functions (\"mean\" by default); can be any function valid in a groupby context\n",
    "fill_value\t|Replace missing values in the result table\n",
    "dropna|\tIf True, do not include columns whose entries are all NA\n",
    "margins|\tAdd row/column subtotals and grand total (False by default)\n",
    "margins_name|\tName to use for the margin row/column labels when passing margins=True; defaults to \"All\"\n",
    "observed|\tWith Categorical group keys, if True, show only the observed category values in the keys rather than all categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Tabulations: Crosstab\n",
    "A cross-tabulation (or crosstab for short) is a special case of a pivot table that computes group frequencies. Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.crosstab(data[\"Nationality\"], data[\"Handedness\"], margins=True) #calculate frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.crosstab([tips[\"time\"], tips[\"day\"]], tips[\"smoker\"], margins=True)# note the first argument is a list of two series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
